# How Social Media Took Us From Tahrir Square to Donald Trump

![rw-book-cover](https://readwise-assets.s3.amazonaws.com/static/images/article0.00998d930354.png)

## Metadata
- Author: [[technologyreview.com]]
- Full Title: How Social Media Took Us From Tahrir Square to Donald Trump
- Category: #articles
- URL: https://www.technologyreview.com/s/611806/how-social-media-took-us-from-tahrir-square-to-donald-trump

## Highlights
- in the 21st century it is the flow of attention, not information (which we already have too much of), that matters.
- Power always learns, and powerful tools always fall into its hands. This is a hard lesson of history but a solid one. It is key to understanding how, in seven years, digital technologies have gone from being hailed as tools of freedom and change to being blamed for upheavals in Western democracies—for enabling increased polarization, rising authoritarianism, and meddling in national elections by Russia and others.
- we also need to examine how human social dynamics, ubiquitous digital connectivity, and the business models of tech giants combine to create an environment where misinformation thrives and even true information can confuse and paralyze rather than informing and illuminating.
- A key issue for me was how microtargeting, especially on Facebook, could be used to wreak havoc with the public sphere. It was true that social media let dissidents know they were not alone, but online microtargeting could also create a world in which you wouldn’t know what messages your neighbors were getting or how the ones aimed at you were being tailored to your desires and vulnerabilities.
- Digital platforms allowed communities to gather and form in new ways, but they also dispersed existing communities, those that had watched the same TV news and read the same newspapers.
- It was a shift from a public, collective politics to a more private, scattered one, with political actors collecting more and more personal data to figure out how to push just the right buttons, person by person and out of sight.
- The NSA seemed to believe that weak security online hurt its adversaries a lot more than it hurt the NSA.
- A Wall Street Journal investigation earlier this year found that YouTube’s recommendation algorithm tended to drive viewers toward extremist content by suggesting edgier versions of whatever they were watching—a good way to hold their attention.
- Twitter’s pithy, rapid-fire format also suits anyone with a professional or instinctual understanding of attention, the crucial resource of the digital economy.
- Donald Trump, as is widely acknowledged, excels at using Twitter to capture attention. But his campaign also excelled at using Facebook as it was designed to be used by advertisers, testing messages on hundreds of thousands of people and microtargeting them with the ones that worked best.
- Dissidents can more easily circumvent censorship, but the public sphere they can now reach is often too noisy and confusing for them to have an impact.
- Those hoping to make positive social change have to convince people both that something in the world needs changing and there is a constructive, reasonable way to change it.
- Authoritarians and extremists, on the other hand, often merely have to muddy the waters and weaken trust in general so that everyone is too fractured and paralyzed to act.
- Second, the new, algorithmic gatekeepers aren’t merely (as they like to believe) neutral conduits for both truth and falsehood. They make their money by keeping people on their sites and apps; that aligns their incentives closely with those who stoke outrage, spread misinformation, and appeal to people’s existing biases and preferences.
- the new gatekeepers succeed by fueling mistrust and doubt, as long as the clicks keep coming.
- Without local checks and balances, local corruption grows and trickles up to feed a global corruption wave playing a major part in many of the current political crises.
- The fourth lesson has to do with the much-touted issue of filter bubbles or echo chambers—the claim that online, we encounter only views similar to our own. This isn’t completely true. While algorithms will often feed people some of what they already want to hear, research shows that we probably encounter a wider variety of opinions online than we do offline, or than we did before the advent of digital tools.
  Rather, the problem is that when we encounter opposing views in the age and context of social media, it’s not like reading them in a newspaper while sitting alone.
- Our cognitive universe isn’t an echo chamber, but our social one is. This is why the various projects for fact-checking claims in the news, while valuable, don’t convince people. Belonging is stronger than facts.
- authoritarians were mobilizing their own supporters to attack the dissidents, defining them as traitors or foreigners. Such “patriotic” trolling and harassment is probably more common, and a bigger threat to dissidents, than attacks orchestrated by governments.
- The content of the argument didn’t matter; they were looking to paralyze and polarize rather than convince.
- This shows, ultimately, that “nobody but us” depended on a mistaken interpretation of what digital security means. The US may well still have the deepest offensive capabilities in cybersecurity. But Podesta fell for a phishing e-mail, the simplest form of hacking, and the US media fell for __attention ­hacking__. Through their hunger for clicks and eyeballs, and their failure to understand how the new digital sphere operates, they were diverted from their core job into a confusing swamp.
    - Tags: [[definition]] 
- Inviting users to “click here to agree” to vague, hard-to-pin-down terms of use doesn’t produce “informed consent.”
- Even the free-for-all environment in which these digital platforms have operated for so long can be seen as a symptom of the broader problem, a world in which the powerful have few restraints on their actions while everyone else gets squeezed.
