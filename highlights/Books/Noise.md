# Noise

![rw-book-cover](https://is4-ssl.mzstatic.com/image/thumb/Publication114/v4/06/59/6f/06596fee-5d9f-aad1-86f5-a4f8430d47ea/9780316451383.jpg/1677x2600bb.jpeg)

## Metadata
- Author: [[Daniel Kahneman, Olivier Sibony & Cass R. Sunstein]]
- Full Title: Noise
- Category: #books

## Highlights
### INTRODUCTION
Two Kinds of Error
- We call Team B biased because its shots are systematically off target.
- We call Team C noisy because its shots are widely scattered
- Bias and noise—systematic deviation and random scatter—are different components of error.
    - Tags: [[definition]] 
- Some judgments are biased; they are systematically off target.
    - Tags: [[definition]] 
- Other judgments are noisy, as people who are expected to agree end up at very different points around the target.
    - Tags: [[definition]] 
- A general property of noise is that you can recognize and measure it while knowing nothing about the target or bias.
- To understand error in judgment, we must understand both bias and noise. Sometimes, as we will see, noise is the more important problem. But in public conversations about human error and in organizations all over the world, noise is rarely recognized. Bias is the star of the show. Noise is a bit player, usually offstage. The topic of bias has been discussed in thousands of scientific articles and dozens of popular books, few of which even mention the issue of noise. This book is our attempt to redress the balance
- To improve the quality of our judgments, we need to overcome noise as well as bias.
- We explore the key advantage of rules, formulas, and algorithms over humans when it comes to making predictions: contrary to popular belief, it is not so much the superior insight of rules but their noiselessness.
- We introduce several noise-reduction techniques that we collect under the label of decision hygiene.
    - Tags: [[definition]] 
- We conclude by offering a system we call the mediating assessments protocol: a general-purpose approach to the evaluation of options that incorporates several key practices of decision hygiene and aims to produce less noisy and more reliable judgments.
    - Tags: [[definition]] 
- What is the right level of noise? Part 6 turns to this question. Perhaps counterintuitively, the right level is not zero. In some areas, it just isn’t feasible to eliminate noise. In other areas, it is too expensive to do so. In still other areas, efforts to reduce noise would compromise important competing values.
- we end each chapter with a few brief propositions in the form of quotations. You can use these statements as they are or adapt them for any issues that matter to you, whether they involve health, safety, education, money, employment, entertainment, or something else. Understanding the problem of noise, and trying to solve it, is a work in progress and a collective endeavor. All of us have opportunities to contribute to this work. This book is written in the hope that we can seize those opportunities.
### PART I
Finding Noise
- noise is unwanted variability, and how can you have variability with singular decisions? In chapter 3, we try to answer this question. The judgment that you make, even in a seemingly unique situation, is one in a cloud of possibilities. You will find a lot of noise there as well.
- The theme that emerges from these three chapters can be summarized in one sentence, which will be a key theme of this book: wherever there is judgment, there is noise—and more of it than you think. Let’s start to find out how much.
#### CHAPTER 1
Crime and Noisy Punishment
- judges have been found more likely to grant parole at the beginning of the day or after a food break than immediately before such a break. If judges are hungry, they are tougher.
  A study of thousands of juvenile court decisions found that when the local football team loses a game on the weekend, the judges make harsher decisions on the Monday (and, to a lesser extent, for the rest of the week).
- A review of 207,000 immigration court decisions over four years found a significant effect of daily temperature variations: when it is hot outside, people are less likely to get asylum.
- The price of reducing noise was to make decisions unacceptably mechanical.
- After the guidelines became advisory, judges became more likely to base their sentencing decisions on their personal values. Mandatory guidelines reduce bias as well as noise
- System noise, that is, unwanted variability in judgments that should ideally be identical, can create rampant injustice, high economic costs, and errors of many kinds.
    - Tags: [[definition]] 
- Disagreement is unavoidable wherever judgment is involved.
- Some methods adopted to reduce noise can simultaneously reduce bias as well.
- Speaking of Noise in Sentencing
  “Experiments show large disparities among judges in the sentences they recommend for identical cases. This variability cannot be fair. A defendant’s sentence should not depend on which judge the case happens to be assigned to.”
  “Criminal sentences should not depend on the judge’s mood during the hearing, or on the outside temperature.”
  “Guidelines are one way to address this issue. But many people don’t like them, because they limit judicial discretion, which might be necessary to ensure fairness and accuracy. After all, each case is unique, isn’t it?”
    - Tags: [[reference]] 
#### CHAPTER 2
A Noisy System
- Disagreement emerged when it came to its magnitude. The executives doubted that noise could be a substantial problem for their company. Much to their credit, however, they agreed to settle the question by a kind of simple experiment that we will call a noise audit
    - Tags: [[definition]] 
- For any risk, there is a Goldilocks price that is just right—neither too high nor too low—and there is a good chance that the average judgment of a large group of professionals is not too far from this Goldilocks number. Prices that are higher or lower than this number are costly—this is how the variability of noisy judgments hurts the bottom line
- We use the word lottery to emphasize the role of chance in the selection of one underwriter or adjuster. In the normal operation of the company, a single professional is assigned to a case, and no one can ever know what would have happened if another colleague had been selected instead.
    - Tags: [[definition]] 
- Imagine an insurance company whose underwriters are noiseless and set the optimal premium, but a chance device then intervenes to modify the quote that the client actually sees. Evidently, there would be no justification for such a lottery. Neither is there any justification for a system in which the outcome depends on the identity of the person randomly chosen to make a professional judgment.
- A noise audit—like the one conducted on federal judges with respect to sentencing—is a way to reveal noise. In such an audit, the same case is evaluated by many individuals, and the variability of their responses is made visible.
- To prepare for the noise audit, executives of the company constructed detailed descriptions of five representative cases for each group (underwriters and adjusters). Employees were asked to evaluate two or three cases each, working independently. They were not told that the purpose of the study was to examine the variability of their judgments
- We asked numerous executives in the company for their answers, and in subsequent years, we have obtained estimates from a wide variety of people in different professions. Surprisingly, one answer is clearly more popular than all others. Most executives of the insurance company guessed 10% or less. When we asked 828 CEOs and senior executives from a variety of industries how much variation they expected to find in similar expert judgments, 10% was also the median answer and the most frequent one (the second most popular was 15%).
- By our measure, the median difference in underwriting was 55%, about five times as large as was expected by most people, including the company’s executives.
    - Note: I guessed 5o%
- For claims adjusters, the median ratio was 43%. We stress that these results are medians: in half the pairs of cases, the difference between the two judgments was even larger.
    - Note: I guessed 59%
- One senior executive estimated that the company’s annual cost of noise in underwriting—counting both the loss of business from excessive quotes and the losses incurred on underpriced contracts—was in the hundreds of millions of dollars.
- A defining feature of system noise is that it is unwanted, and we should stress right here that variability in judgments is not always unwanted.
- Variability in judgments is also expected and welcome in a competitive situation in which the best judgments will be rewarded. When several companies (or several teams in the same organization) compete to generate innovative solutions to the same customer problem, we don’t want them to focus on the same approach. The same is true when multiple teams of researchers attack a scientific problem, such as the development of a vaccine: we very much want them to look at it from different angles.
- In such settings, variability in ideas and judgments is again welcome, because variation is only the first step. In a second phase, the results of these judgments will be pitted against one another, and the best will triumph. In a market as in nature, selection cannot work without variation.
  Matters of taste and competitive settings all pose interesting problems of judgment. But our focus is on judgments in which variability is undesirable. System noise is a problem of systems, which are organizations, not markets.
- Median noise, measured in the same way as in the insurance company, was 41%. Such large differences among investors in the same firm, using the same valuation methods, cannot be good news.
- A frequent misconception about unwanted variability in judgments is that it doesn’t matter, because random errors supposedly cancel one another out. Certainly, positive and negative errors in a judgment about the same case will tend to cancel one another out, and we will discuss in detail how this property can be used to reduce noise. But noisy systems do not make multiple judgments of the same case. They make noisy judgments of different cases.
- In noisy systems, errors do not cancel out. They add up.
- What did surprise us, however, was the reaction of the executives to whom we reported our findings: no one at the company had expected anything like the amount of noise we had observed. No one questioned the validity of the audit, and no one claimed that the observed amount of noise was acceptable. Yet the problem of noise—and its large cost—seemed like a new one for the organization. Noise was like a leak in the basement. It was tolerated not because it was thought acceptable but because it had remained unnoticed.
- The noise audits suggested that respected professionals—and the organizations that employ them—maintained an illusion of agreement while in fact disagreeing in their daily professional judgments.
    - Tags: [[definition]] 
- Most of us, most of the time, live with the unquestioned belief that the world looks as it does because that’s the way it is. There is one small step from this belief to another: “Other people view the world much the way I do.” These beliefs, which have been called naive realism, are essential to the sense of a reality we share with other people. We rarely question these beliefs. We hold a single interpretation of the world around us at any one time, and we normally invest little effort in generating plausible alternatives to it. One interpretation is enough, and we experience it as true. We do not go through life imagining alternative ways of seeing what we see
    - Tags: [[definition]] 
- In the case of professional judgments, the belief that others see the world much as we do is reinforced every day in multiple ways. First, we share with our colleagues a common language and set of rules about the considerations that should matter in our decisions. We also have the reassuring experience of agreeing with others on the absurdity of judgments that violate these rules. We view the occasional disagreements with colleagues as lapses of judgment on their part. We have little opportunity to notice that our agreed-on rules are vague, sufficient to eliminate some possibilities but not to specify a shared positive response to a particular case. We can live comfortably with colleagues without ever noticing that they actually do not see the world as we do.
- Confidence is nurtured by the subjective experience of judgments that are made with increasing fluency and ease, in part because they resemble judgments made in similar cases in the past.
- How had the leaders of the company remained unaware of their noise problem? There are several possible answers here, but one that seems to play a large role in many settings is simply the discomfort of disagreement. Most organizations prefer consensus and harmony over dissent and conflict. The procedures in place often seem expressly designed to minimize the frequency of exposure to actual disagreements and, when such disagreements happen, to explain them away
- Consider another mechanism that many companies resort to: postmortems of unfortunate judgments. As a learning mechanism, postmortems are useful. But if a mistake has truly been made—in the sense that a judgment strayed far from professional norms—discussing it will not be challenging. Experts will easily conclude that the judgment was way off the consensus. (They might also write it off as a rare exception.) Bad judgment is much easier to identify than good judgment. The calling out of egregious mistakes and the marginalization of bad colleagues will not help professionals become aware of how much they disagree when making broadly acceptable judgments. On the contrary, the easy consensus about bad judgments may even reinforce the illusion of agreement. The true lesson, about the ubiquity of system noise, will never be learned
- Speaking of System Noise in the Insurance Company
  “We depend on the quality of professional judgments, by underwriters, claims adjusters, and others. We assign each case to one expert, but we operate under the wrong assumption that another expert would produce a similar judgment.”
  “System noise is five times larger than we thought—or than we can tolerate. Without a noise audit, we would never have realized that. The noise audit shattered the illusion of agreement.”
  “System noise is a serious problem: it costs us hundreds of millions.”
  “Wherever there is judgment, there is noise—and more of it than we think.”
    - Tags: [[reference]] 
#### CHAPTER 3
Singular Decisions
- The case studies we have discussed thus far involve judgments that are made repeatedly. What is the right sentence for someone convicted of theft? What is the right premium for a particular risk? While each case is in some sense unique, judgments like these are recurrent decisions.
    - Tags: [[definition]] 
- Noise in recurrent decisions is demonstrated by a noise audit
- It seems much harder, or perhaps even impossible, to apply the idea of noise to a category of judgments that we call singular decisions
    - Tags: [[definition]] 
- Decisions that are made only once, like the president’s Ebola response, are singular because they are not made recurrently by the same individual or team, they lack a prepackaged response, and they are marked by genuinely unique features
- Arguably, there is a continuum, not a category difference, between singular and recurrent decisions.
- Analyses of recurrent decisions have often taken a statistical bent, with social scientists assessing many similar decisions to discern patterns, identify regularities, and measure accuracy. In contrast, discussions of singular decisions typically adopt a causal view; they are conducted in hindsight and are focused on identifying the causes of what happened. Historical analyses, like case studies of management successes and failures, aim to understand how an essentially unique judgment was made.
- we cannot measure noise in a singular decision, but if we think counterfactually, we know for sure that noise is there.
- when you make a singular decision, you have to imagine that another decision maker, even one just as competent as you and sharing the same goals and values, would not reach the same conclusion from the same facts. And as the decision maker, you should recognize that you might have made a different decision if some irrelevant aspects of the situation or of the decision-making process had been different
- our inability to observe variability would not make the decision less noisy.
- If singular decisions are just as noisy as recurrent ones, then the strategies that reduce noise in recurrent decisions should also improve the quality of singular decisions.
- From the perspective of noise reduction, a singular decision is a recurrent decision that happens only once. Whether you make a decision only once or a hundred times, your goal should be to make it in a way that reduces both bias and noise. And practices that reduce error should be just as effective in your one-of-a-kind decisions as in your repeated ones.
- Speaking of Singular Decisions
  “The way you approach this unusual opportunity exposes you to noise.”
  “Remember: a singular decision is a recurrent decision that is made only once.”
  “The personal experiences that made you who you are are not truly relevant to this decision.”
    - Tags: [[reference]] 
### PART II
Your Mind Is a Measuring Instrument
- Measurement, in everyday life as in science, is the act of using an instrument to assign a value on a scale to an object or event
    - Tags: [[definition]] 
- Judgment can therefore be described as measurement in which the instrument is a human mind. Implicit in the notion of measurement is the goal of accuracy—to approach truth and minimize error. The goal of judgment is not to impress, not to take a stand, not to persuade. It is important to note that the concept of judgment as we use it here is borrowed from the technical psychological literature, and that it is a much narrower concept than the same word has in everyday language. Judgment is not a synonym for thinking, and making accurate judgments is not a synonym for having good judgment.
  As we define it, a judgment is a conclusion that can be summarized in a word or phrase.
    - Tags: [[definition]] 
- Although accuracy is the goal, perfection in achieving this goal is never achieved even in scientific measurement, much less in judgment. There is always some error, some of which is bias and some of which is noise.
- We can think of most judgments, specifically predictive judgments, as similar to the measurements you just made. When we make a prediction, we attempt to come close to a true value. An economic forecaster aims to be as close as possible to the true value of the growth in next year’s gross domestic product; a doctor aims to make the correct diagnosis. (Note that the term prediction, in the technical sense used in this book, does not imply predicting the future: for our purposes, the diagnosis of an existing medical condition is a prediction.)
    - Tags: [[definition]] 
#### CHAPTER 4
Matters of Judgment
- A matter of judgment is one with some uncertainty about the answer and where we allow for the possibility that reasonable and competent people might disagree.
  But there is a limit to how much disagreement is admissible. Indeed, the word judgment is used mainly where people believe they should agree. Matters of judgment differ from matters of opinion or taste, in which unresolved differences are entirely acceptable.
- Matters of judgment, including professional judgments, occupy a space between questions of fact or computation on the one hand and matters of taste or opinion on the other. They are defined by the expectation of bounded disagreement.
    - Tags: [[definition]] 
- Of all the cues provided by the description (which are only a subset of what you might need to know), you attended to some more than others without being fully aware of the choices you made.
- Selective attention and selective recall are a source of variability across people.
- Incidentally, you may have noticed that the stopwatch exercise and the Gambardi problem illustrate two types of noise. The variability of judgments over successive trials with the stopwatch is noise within a single judge (yourself), whereas the variability of judgments of the Gambardi case is noise between different judges. In measurement terms, the first problem illustrates within-person reliability, and the second illustrates between-person reliability.
    - Tags: [[definition]] 
- The Gambardi exercise is an example of a nonverifiable predictive judgment, for two separate reasons: Gambardi is fictitious and the answer is probabilistic.
  Many professional judgments are nonverifiable.
    - Tags: [[definition]] 
- Verifiability does not change the experience of judgment. To some degree, you might perhaps think harder about a problem whose answer will be revealed soon, because the fear of being exposed concentrates the mind. Conversely, you might refuse to give much thought to a problem so hypothetical as to be absurd ... But, by and large, you address a plausible, hypothetical problem in much the same way that you tackle a real one
- What made you feel you got the judgment right, or at least right enough to be your answer? We suggest this feeling is an internal signal of judgment completion, unrelated to any outside information. Your answer felt right if it seemed to fit comfortably enough with the evidence. An answer of 0 or 100 would not give you that sense of fit: the confidence it implies is inconsistent with the messy, ambiguous, conflicting evidence provided. But the number on which you settled, whatever it is, gave you the sense of coherence you needed. The aim of judgment, as you experienced it, was the achievement of a coherent solution.
  The essential feature of this internal signal is that the sense of coherence is part of the experience of judgment. It is not contingent on a real outcome. As a result, the internal signal is just as available for nonverifiable judgments as it is for real, verifiable ones
    - Tags: [[definition]] 
- Verifiability does not change the experience of judgment as it takes place. It does, however, change its evaluation after the fact.
- Verifiable judgments can be scored by an objective observer on a simple measure of error: the difference between the judgment and the outcome
- there is a second way to evaluate judgments. This approach applies both to verifiable and nonverifiable ones. It consists in evaluating the process of judgment.
- When we speak of good or bad judgments, we may be speaking either about the output (e.g., the number you produced in the Gambardi case) or about the process—what you did to arrive at that number.
- In summary, what people usually claim to strive for in verifiable judgments is a prediction that matches the outcome. What they are effectively trying to achieve, regardless of verifiability, is the internal signal of completion provided by the coherence between the facts of the case and the judgment. And what they should be trying to achieve, normatively speaking, is the judgment process that would produce the best judgment over an ensemble of similar cases.
- Sentencing a felon is not a prediction. It is an evaluative judgment that seeks to match the sentence to the severity of the crime. Judges at a wine fair and restaurant critics make evaluative judgments. Professors who grade essays, judges at ice-skating competitions, and committees that award grants to research projects make evaluative judgments.
  A different kind of evaluative judgment is made in decisions that involve multiple options and trade-offs between them. Consider managers who choose among candidates for hiring, management teams that must decide on strategic options, or even presidents choosing how to respond to an epidemic in Africa. To be sure, all these decisions rely on predictive judgments that provide input—for instance, how a candidate will perform in her first year, how the stock market will respond to a given strategic move, or how quickly the epidemic will spread if left unchecked. But the final decisions entail trade-offs between the pros and cons of various options, and these trade-offs are resolved by evaluative judgments.
    - Tags: [[definition]] 
- Like predictive judgments, evaluative judgments entail an expectation of bounded disagreement.
- The observation of noise in predictive judgments always indicates that something is wrong. If two doctors disagree on a diagnosis or two forecasters disagree about the next quarter’s sales, at least one of them must be in error.
- Noise in evaluative judgments is problematic for a different reason. In any system in which judges are assumed to be interchangeable and assigned quasi-randomly, large disagreements about the same case violate expectations of fairness and consistency.
- System noise is inconsistency, and inconsistency damages the credibility of the system.
- All we need to measure noise is multiple judgments of the same problem.
- Speaking of Professional Judgment
  “This is a matter of judgment. You can’t expect people to agree perfectly.”
  “Yes, this is a matter of judgment, but some judgments are so far out that they are wrong.”
  “Your choice between the candidates was just an expression of taste, not a serious judgment.”
  “A decision requires both predictive and evaluative judgments.”
    - Tags: [[reference]] 
#### CHAPTER 5
Measuring Error
- in professional judgments of all kinds, whenever accuracy is the goal, bias and noise play the same role in the calculation of overall error. In some cases, the larger contributor will be bias; in other cases it will be noise (and these cases are more common than one might expect). But in every case, a reduction of noise has the same impact on overall error as does a reduction of bias by the same amount. For that reason, the measurement and reduction of noise should have the same high priority as the measurement and reduction of bias.
- we can compute the standard deviation of the forecasts. As its name indicates, the standard deviation represents a typical distance from the mean. In this example, it is 10 percentage points. As is true for every normal distribution, about two-thirds of the forecasts are contained within one standard deviation on either side of the mean
    - Tags: [[definition]] 
- Bias is simply the average of errors
- Gauss proposed a rule for scoring the contribution of individual errors to overall error. His measure of overall error—called mean squared error (MSE)—is the average of the squares of the individual errors of measurement.
    - Tags: [[definition]] 
- There is a tight link between this problem of estimation, about which you have a clear intuition, and the problem of overall error measurement that concerns us here. They are, in fact, two sides of the same coin. That is because the best estimate is one that minimizes the overall error of the available measurements. Accordingly, if your intuition about the mean being the best estimate is correct, the formula you use to measure overall error should be one that yields the arithmetic mean as the value for which error is minimized.
  MSE has that property—and it is the only definition of overall error that has it.
- The role of bias and noise in error is easily summarized in two expressions that we will call the error equations. The first of these equations decomposes the error in a single measurement into the two components with which you are now familiar: bias—the average error—and a residual “noisy error.” The noisy error is positive when the error is larger than the bias, negative when it is smaller. The average of noisy errors is zero. Nothing new in the first error equation.
  Error in a single measurement = Bias + Noisy Error
  The second error equation is a decomposition of MSE, the measure of overall error we have now introduced. Using some simple algebra, MSE can be shown to be equal to the sum of the squares of bias and noise. (Recall that noise is the standard deviation of measurements, which is identical to the standard deviation of noisy errors.) Therefore:
  Overall Error (MSE) = Bias^2 + Noise^2
- As the mathematical expression and its visual representation both suggest, bias and noise play identical roles in the error equation. They are independent of each other and equally weighted in the determination of overall error
- how will reductions in either noise or bias by the same amount affect overall error? The answer is straightforward: bias and noise are interchangeable in the error equation, and the decrease in overall error will be the same, regardless of which of the two is reduced
- As this example illustrates, MSE conflicts with common intuitions about the scoring of predictive judgments. To minimize MSE, you must concentrate on avoiding large errors.
- Unfortunately, people’s intuitions in this regard are almost the mirror image of what they should be: people are very keen to get perfect hits and highly sensitive to small errors, but they hardly care at all about the difference between two large errors. Even if you sincerely believe that your goal is to make accurate judgments, your emotional reaction to results may be incompatible with the achievement of accuracy as science defines it.
- noise reduction makes bias more visible
- Of course, it is always desirable to carry out a noise audit on multiple cases at once. Nothing changes. The error equation is applied to the separate cases; and an overall equation is obtained by taking the averages of MSE, bias squared and noise squared over the cases.
- statistical bias is not a synonym for social discrimination; it is simply the average error in a set of judgments
- accuracy (the least bias) and precision (the least noise)
- The error equation does not apply to evaluative judgments, however, because the concept of error, which depends on the existence of a true value, is far more difficult to apply. Furthermore, even if errors could be specified, their costs would rarely be symmetrical and would be unlikely to be precisely proportional to their square.
- A widely accepted maxim of good decision making is that you should not mix your values and your facts. Good decision making must be based on objective and accurate predictive judgments that are completely unaffected by hopes and fears, or by preferences and values.
- In all these examples, the final decisions require evaluative judgments. The decision makers must consider multiple options and apply their values to make the optimal choice. But the decisions depend on underlying predictions, which should be value-neutral.
- Speaking of the Error Equation
  “Oddly, reducing bias and noise by the same amount has the same effect on accuracy.”
  “Reducing noise in predictive judgment is always useful, regardless of what you know about bias.”
  “When judgments are split 84 to 16 between those that are above and below the true value, there is a large bias—that’s when bias and noise are equal.”
  “Predictive judgments are involved in every decision, and accuracy should be their only goal. Keep your values and your facts separate.”
    - Tags: [[reference]] 
#### CHAPTER 6
The Analysis of Noise
- When we focus on a single case, all variability of judgment is error, and the two constituents of error are bias and noise.
- First, the participants in the noise audit dealt with artificial cases, which were unusually easy to compare and were presented in immediate succession. Real life does not provide nearly as much support for the maintenance of consistency. Second, judges in a courtroom have much more information than they had here. New information, unless it is decisive, provides more opportunities for judges to differ from one another. For these reasons, we suspect that the amount of noise defendants face in actual courtrooms is even larger than what we see here.
